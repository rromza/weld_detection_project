import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os

class WeldClassifier(nn.Module):
    """ÐšÐ»Ð°ÑÑ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ ÑÐ²Ð°Ñ€Ð½Ñ‹Ñ… ÑˆÐ²Ð¾Ð²"""
    def __init__(self, config):
        super(WeldClassifier, self).__init__()
        self.config = config
        
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        if config['MODEL_NAME'] == 'efficientnet_b0':
            backbone = models.efficientnet_b0(weights=None)
            in_features = 1280
        elif config['MODEL_NAME'] == 'efficientnet_b1':
            backbone = models.efficientnet_b1(weights=None)
            in_features = 1280
        elif config['MODEL_NAME'] == 'efficientnet_b2':
            backbone = models.efficientnet_b2(weights=None)
            in_features = 1408
        else:
            raise ValueError(f"Model {config['MODEL_NAME']} not supported")
        
        # Ð—Ð°Ð¼Ð¾Ñ€Ð°Ð¶Ð¸Ð²Ð°ÐµÐ¼ backbone (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
        for param in backbone.parameters():
            param.requires_grad = False
        
        # ÐœÐµÐ½ÑÐµÐ¼ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€
        backbone.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, config['NUM_CLASSES'])
        )
        
        self.model = backbone
    
    def forward(self, x):
        return self.model(x)

def load_model(model_path, device='cpu'):
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¸Ð· Ñ„Ð°Ð¹Ð»Ð°
    
    Args:
        model_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ñ„Ð°Ð¹Ð»Ñƒ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        device: ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ (cpu Ð¸Ð»Ð¸ cuda)
    
    Returns:
        model: Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        config: ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        class_names: Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ»Ð°ÑÑÐ¾Ð²
    """
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
    config = checkpoint['config']
    class_names = checkpoint['classes']
    
    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
    model = WeldClassifier(config)
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð²ÐµÑÐ°
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()  # ÐŸÐµÑ€ÐµÐ²Ð¾Ð´Ð¸Ð¼ Ð² Ñ€ÐµÐ¶Ð¸Ð¼ Ð¸Ð½Ñ„ÐµÑ€ÐµÐ½ÑÐ°
    
    print(f"âœ… Model loaded from {model_path}")
    print(f"ðŸ“Š Classes: {class_names}")
    print(f"âš™ï¸  Device: {device}")
    
    return model, config, class_names

def get_transforms(input_size=224):
    """
    Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
    
    Args:
        input_size: Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð²Ñ…Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    
    Returns:
        transform: ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¹
    """
    return transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

def predict_image(model, image, transform, device='cpu', class_names=None):
    """
    ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ° Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    
    Args:
        model: Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        image: PIL Image
        transform: Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        device: ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾ Ð´Ð»Ñ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ð¹
        class_names: Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ ÐºÐ»Ð°ÑÑÐ¾Ð²
    
    Returns:
        pred_class: Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¹ ÐºÐ»Ð°ÑÑ (ÑÑ‚Ñ€Ð¾ÐºÐ°)
        confidence: ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        all_probs: Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ð²ÑÐµÑ… ÐºÐ»Ð°ÑÑÐ¾Ð²
    """
    # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
    image_tensor = transform(image).unsqueeze(0).to(device)
    
    # ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        confidence, predicted_idx = torch.max(probabilities, 1)
    
    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ð² numpy
    confidence = confidence.item()
    predicted_idx = predicted_idx.item()
    all_probs = probabilities.cpu().numpy()[0]
    
    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ ÐºÐ»Ð°ÑÑÐ°
    if class_names:
        pred_class = class_names[predicted_idx]
    else:
        pred_class = f"Class {predicted_idx}"
    
    return pred_class, confidence, all_probs

def load_and_prepare_image(image_path, max_size=800):
    """
    Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¸ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    
    Args:
        image_path: Ð¿ÑƒÑ‚ÑŒ Ðº Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ
        max_size: Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
    
    Returns:
        image: PIL Image
    """
    image = Image.open(image_path).convert('RGB')
    
    # ÐœÐ°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ (ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ Ð¿Ñ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¸)
    width, height = image.size
    if max(width, height) > max_size:
        ratio = max_size / max(width, height)
        new_size = (int(width * ratio), int(height * ratio))
        image = image.resize(new_size, Image.Resampling.LANCZOS)
    
    return image